{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average per day when you have monthly sums\n",
    "\n",
    "Just occasionally I end up with dealing with data representing monthly sums (like sales in Â£ per month, or similar). To smooth out the fact that different months have different numbers of days, it can be handy to break this down into averages per day.\n",
    "\n",
    "Assuming you have a DateTimeIndex, this little function in combination with pandas `apply` method gets the job done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg_per_day_in_month(x):\n",
    "    if x.name.month in [1,3,5,7,8,10,12]:\n",
    "        return x/31\n",
    "    elif x.name.month in [4,6,9,11]:\n",
    "        return x/30\n",
    "    elif x.name.month == 2:\n",
    "        if x.name.year % 4 == 0:\n",
    "            return x/29\n",
    "        else:\n",
    "            return x/28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage would be something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped_by_month['average_per_day'] = grouped_by_month.apply(avg_per_day_in_month, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to feed variables into a function within agg/apply/transform etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say you wanted to divide the minimum value in a group by a number. But you wanted flexibility about what that number should be... how do you do it?\n",
    "\n",
    "The answer is to feed a function within a function, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def divide(a):\n",
    "    def divide_(x):\n",
    "        return x.min()/a\n",
    "    return divide_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You would then use it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.groupby('group_key').agg({'column_name': divide(3)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning categorical variables into one-hot columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I feel that this should be easier than it is (unless there is some new pandas wizardry that I'm not aware of). Either way, it's a common job to turn categorical columns into dummy columns. Scikit-learn, in particular, doesn't like strings, so you really need this if you've got categorical variables and you're using Python for machine learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dummy_columns(df, list_of_cols, drop_columns = True):\n",
    "    \"\"\"\n",
    "    Function to create dummy columns from the categorical variables\n",
    "    of an input dataframe.\n",
    "    The columns to dummify are specified as a list.\n",
    "    The original columns can be dropped by setting drop_columns = True.\n",
    "    \n",
    "    Inputs - df, the initial dataframe\n",
    "           - list_of_cols, the columns to drop as a list of strings\n",
    "           - drop_columns, whether to drop the categorical columns\n",
    "           \n",
    "    Returns - dummifed dataframe\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    dummy_dfs = [df_copy]\n",
    "    for col in list_of_cols:\n",
    "        dummy_df = pd.get_dummies(df_copy[col])\n",
    "        dummy_dfs.append(dummy_df)\n",
    "        if drop_columns:\n",
    "            df_copy.drop(col, axis = 1, inplace = True)\n",
    "    return pd.concat(dummy_dfs, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the shape of the input/output dataframes are as expected - I haven't yet tested this code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
